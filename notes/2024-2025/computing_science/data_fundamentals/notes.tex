\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage[margin=2px]{geometry}
\title{Data Fundamentals}
\author{}
\date{}

\begin{document}

\small

\subsection*{Arrays}

\noindent \textbf{Basic Concepts}
2 $\times$ 3 means 2 rows, 3 columns.
Rank 1 tensor is 1D array.
concatenate to join along existing dimension.
stack to stack up arrays along new dimension.
Tiling to repeat an array.

\noindent \textbf{Broadcasting}
Broadcasting (x, y) with (x, y), (1, y), (x, 1), (y,).

\noindent \textbf{Reduction and Accumulation}
Reduction: apply a function to reduce the array to a single value.
or with axis to reduce along a specific axis.
Accumulate: apply a function to reduce the array to a single value.

% TODO: Probably can remove this section, or at least reduce it.
\noindent \textbf{NumPy Functions}
\begin{itemize}
    \item \texttt{np.loadtxt}, \texttt{np.savetxt}, \texttt{np.zeros}, \texttt{np.ones}, \texttt{np.full}, \texttt{np.empty}, \texttt{np.zeros\_like}, \texttt{np.ones\_like}, \texttt{np.full\_like}, \texttt{np.empty\_like}, \texttt{np.arange}, \texttt{np.linspace}, \texttt{np.array}, \texttt{np.meshgrid}
    \item \texttt{np.random.uniform}, \texttt{np.random.normal}, \texttt{np.random.randint}, \texttt{np.random.choice}, \texttt{np.random.permutation}
    \item \texttt{np.tile}, \texttt{np.transpose}, \texttt{x.T}, \texttt{np.stack}, \texttt{np.concatenate}, \texttt{np.squeeze}, \texttt{np.reshape}, \texttt{np.einsum}, \texttt{np.ravel}, \texttt{np.swapaxes}, \texttt{np.rollaxes}
    \item \texttt{np.minimum}, \texttt{np.maximum}, \texttt{np.add}, \texttt{np.subtract}, \texttt{np.multiply}, \texttt{np.log}, \texttt{np.exp}, \texttt{np.sin}, \texttt{np.cos}, \texttt{np.tan}, \texttt{np.arcsin}, \texttt{np.arccos}, \texttt{np.tanh}
\end{itemize}


\subsection*{Floats}

\noindent \textbf{Float Exceptions}
Float exceptions:
Invalid operation, divide by zero, overflow, underflow, inexact.
np.allclose.

\noindent \textbf{Stride and Representation}
Stride: number of bytes between each element in an axis.
float = sign * 2\^{exponent} * 1.mantissa
dope vector:
numpy arrays hold dopy vectors: stiding information.

\noindent \textbf{Rank and Dimensions}
Rank preserving: The number of dimensions is the same.
Rank reducing: The number of dimensions is reduced.
Rank promoting: The number of dimensions is increased.
Add singleton dimensions: x[:, np.newaxis]
Remove singleton dimensions: np.squeeze (x)
Elided axes: [0, \ldots, 4]
Swapping and rearranging: np.swapaxes, np.rollaxis, np.moveaxis, np.transpose
Einsum: Einstein summation convention. Used to reorder high-dimensional arrays.

\subsection*{Scientific Visualisation}

\noindent \textbf{Basic Terminology}
A \textbf{stat} computes statistics from data, such as means (mean, median, max, min,  etc.)
A \textbf{mapping} transforms data attributes into visual values.
A \textbf{scale} specifies how units are transformed.
A \textbf{coord} system connects mapped data onto points on a plane.
A \textbf{guide} provides visual references like tick marks, labels, and legends to explain the mapping's meaning.
A \textbf{geom} is the geometric representation of mapped data.
A \textbf{layer} consists of one set of geoms with one mapping on one coordinate system, and multiple layers can be overlaid.
A \textbf{facet} shows a different view of the same dataset on a separate coordinate system.
A \textbf{figure} is a collection of one or more facets. Finally.
A \textbf{caption} explains the visualization to the reader.

\noindent Avoid rescaled units. Facet: different view of the same dataset.
Regression: fit a line to the data. Smoothing: fit a curve to the data.

\noindent \textbf{Geoms and Aesthetics}
\noindent Geoms: markers: geoms that represent bare points.
Colour changes: percaptually uniform, monotonic brightness.

\noindent Geometric representations, or \textbf{geoms}, that connect points together should be used if it makes sense to ask what is between two data points.
\textbf{Line styles} can have variable thickness, variable color, and dash patterns to enhance the visual representation of the data.

\noindent For example, the staircase plot is useful when we know that the value cannot have changed between measurements (e.g., in a coin toss scenario).
This type of plot connects points but keeps the value fixed until a new data point is observed.
Conversely, if measurements are naturally discrete, a bar chart may be more suitable to represent the data effectively.

\noindent \textbf{Transparency (Alpha)}
\noindent A \textbf{geom} can be rendered with different levels of transparency,
referred to as \textbf{alpha} (equivalent to opacity) or
\textbf{transparency} (the inverse of opacity).
This feature is particularly useful when dealing with a large number
of overlapping geoms, as it allows for the emphasis of certain geoms
while maintaining visibility of others.
However, it is important to use transparency judiciously, as excessive
transparency can make graphs difficult to read.

\noindent \textbf{Axes and Coordinates}
Axis limits specify a range in data units which are then mapped onto the available space in the figure in visual units.
log scales: semilog, loglog. Symmetric log scales: logit, log.
polar coordinates: useful for circular data.

\noindent \textbf{Facets and Layers}
acets and layers: ways of crating graphs with multiple geoms.
\textbf{Distinct layers} superimposed on the same set of coords.
\textbf{Distinct facets} on separate sets of coords.

\noindent \textbf{Communicating Uncertainty}


\subsection*{Linear Algebra}

% Week 4

\noindent \textbf{Weighted Sums of Vectors}
$\lambda_1 \mathbf{x}_1 + \lambda_2 \mathbf{x}_2 + \cdots + \lambda_n \mathbf{x}_n$
\textbf{Linear interpolation}
$lerp(x_1, x_2, \alpha) = (1 - \alpha)x_1 + (\alpha)x_2$

\noindent \textbf{Norms}
$||x||_p = {(\sum_{i=1}^{n} |x_i|^p)}^{\frac{1}{p}}$
$||x||_\infty = \max_{i=1}^{n} |x_i|$
$||x||_{-\infty} = \min_{i=1}^{n} |x_i|$
\textbf{Normalisation} $x' = \frac{x}{||x||_p}$

\noindent \textbf{Cosine Distance}
$\cos \theta = \frac{\mathbf{x} \cdot \mathbf{y}}{||\mathbf{x}|| \, ||\mathbf{y}||}$

\noindent \textbf{Variance}
$\sigma^2 = \frac{1}{N - 1} \sum_{i=0}^{N-1} {(x_i - \mu)}^2$

\noindent \textbf{Covariance Matrices}.
We compute the covariance of every dimension with every other dimension.
$\Sigma_{ij} = \frac{1}{N - 1} \sum_{k=1}^{N} (X_{ki} - \mu_i)(X_{kj} - \mu_j)$.
You can also use $np.cov$.


% Week 5

\noindent \textbf{Adjacency Matrices} square matrix of $|V| \times |V|$ size (where $|V| =$ vertices) where no edge from $V_i$ to $V_j$ means 0 and existing edges mean 1
\textbf{Out-degree} sum across the rows
\textbf{In-degree} sum across the columns
\textbf{Symmetric matrix} means an undirected graph
directed graph can be turned into an undirected one using: $A` = A + A^T$.
The Laplacian matrix of a graph is $L = D - A$, where $D$ is the degree matrix and $A$ is the adjacency matrix.
$D_{ii} = \sum_{j=1}^{|V|} A_{ij}$
\textbf{A Sparse Matrix} is a matrix with a large number of zero elements, the oppisite is a \textbf{Dense Matrix}.
\textbf{A Stochastic Matrix} is a square matrix of non-negative numbers with each row summing to 1.
\textbf{A Doubly Stochastic Matrix} is a square matrix of non-negative numbers with each row and column summing to 1.
\textbf{Eigenvector} of A is a vector that is only scaled when is applied to it, not rotated.
\textbf{Eigenvalue} of A is how much the eigenvector is scaled by when is applied to it.
$A\vec{x} = \lambda  \vec{x}$.
\textbf{Power Iteration}
$\vec{x_n} = \frac{A \vec{x_{n-1}}}{\|A\vec{x_{n-1}}\|_\infty}$.
$evals, evecs = np.linalg.eigh(A)$.
The \textbf{eigenspectrum} is just the sequence of absolute eigenvalues, ordered by magnitude.

\noindent \textbf{Principle Components Analysis}
The eigenvectors of the covariance matrix are called the \textbf{principal components}, and they tell us the
directions in which the data varies most.
The direction of principal component $i$ is given by the eigenvector $\vec{x}_i$, and the length of the
component is given by $\sqrt{\lambda_i}$.

\noindent \textbf{The Trace} of a matrix is the sum of its diagonal elements.
\textbf{The Determinant} of a matrix is the product of the eigenvalues: $\text{det}(A) = \prod_{i=1}^n \lambda_i$

\noindent \textbf{Positive Definite Matrices}
A matrix is positive definite if all its eigenvalues are greater than zero: $\lambda_i > 0$.

\noindent \textbf{Positive Semi-Definite Matrices}
A matrix is positive semi-definite if all its eigenvalues are non-negative: $\lambda_i \geq 0$.

\noindent A positive definite mathrix has the property $\vec{x}^T A \vec{x} > 0$ for all nonzero vectors $\vec{x}$.
This tells us that the dot product of $\vec{x}$ with $A \vec{x}$ must be positive
(N.B. $A \vec{x}$ is the vector obtained by transforming $\vec{x}$ with $A$).
This can only happen if the angle $\theta$ between $\vec{x}$ and $A \vec{x}$ is less than $90^\circ$,

\noindent Eigenvectors exist only for square matrices.
A matrix $A$ transforms a general vector by rotating and scaling it.
However, the eigenvectors of $A$ are special because they can only be scaled, not rotated by the transform.
The eigenvalues of $A$ are the scaling factors $\lambda_i$ that correspond to each unit eigenvector $\vec{x}_i$.
Eigendecomposition is the process of breaking a matrix down into its constituent eigenvalues
and eigenvectors. These serve as a compact summary of the matrix.
The eigenspectrum is just the list of (absolute) eigenvalues of a matrix, in rank order, largest first.
If we have a complete set of eigenvectors and eigenvalues, we can reconstruct the matrix.
We can approximate a large matrix with a few leading eigenvectors; this is a simplified or
truncated approximation to the original matrix.
If we repeatedly apply a matrix to some vector, the vector will be stretched more and more
along the largest eigenvectors.

\noindent \textbf{An orthogonal matrix} is a square matrix with orthonormal columns, $A^T = A^{-1}$.

\noindent \textbf{Key Algorithm I\@: Singular Value Decomposition}
A general approach to decomposing any matrix A.
$A = U \Sigma V^T$

\noindent $U$ is a \textbf{square unitary mxn matrix}, whose columns contain the left singular vectors,
$V$ is an \textbf{square unitary nxn matrix}, whose columns contain the right singular vectors,
$\Sigma$ is a \textbf{diagonal mxn matrix}, whose diagonal contains the singular values

\noindent A \textbf{unitary matrix} is one whose conjugate transpose is equal to its inverse.
The SVD is the same as:
Taking the eigenvectors of $A^T A$ to get $U$
Taking the square root of the absolute value of the eigenvalues $\lambda_i$ of $A^T A$ to get $\Sigma_i = \sqrt{\lambda_i}$
Taking the eigenvectors of $A A^T$ to get $V^T$
$A^n = V \Sigma^n U^T$

\noindent \textbf{Pseudo-inverse}
We can also pseudo-inverse a matrix A+ even if A is not square.
$A^+ = V \Sigma^{-1} U^T$

\noindent the \textbf{Rank} of a matrix is the number of non-zero singular values,
or the number of linearly independent rows or columns.

\noindent The \textbf{condition number} of a matrix is the ratio of the largest singular value to the smallest.

\noindent \textbf{Whitening} removes all linear correlations within a dataset.
$X^{\text w} = (X - \vec{\mu}) \Sigma^{-1/2}$ where $\vec{\mu}$ is the mean vector, i.e.
A row vector containing the mean of each column in $X$, and $\Sigma$ is the covariance matrix.

% Week 6

\subsection*{Optimisation}
\textbf{Paremeters} are things we can adjust (inputs), they exist in a parameter space: the set of all possible values.

\noindent \textbf{Objective Function} (loss function) maps the parameters onto a single numerical measure of how good the configuration is.
The desired output of the optimisation algorithm is the parameter configuration that minimises the objective function.
$\theta^* = \arg \min_{\theta \in \Theta} \text{L}(\theta)$

\noindent \textbf{Constraints} are limitations on the parameters. This defines a region of the parameter space that is feasible,
the feasible set or region.

\noindent It is common to have express problems in a form where the objective function is a distance between an output
and a reference is measured.

\noindent \textbf{Evaluating the objective function} may be expensive, so a good optimisation algorithm will find the optimal
configuration with few queries.

\noindent \textbf{Discrete and continuous} optimisation are inferred based on the parameter space.

\noindent \textbf{Constraint types}: box constraint, convex constraint (collection of inequalities).
equiality and inequality constraint.

\noindent \textbf{Constrained optimisation} could speed it up, though fewer algorithms are available for optimisation.
May be hard to specify feasible region.

\noindent \textbf{Soft constraints} work by applying penalties to the objecive function to `discourage' solutions that violate the constraints.

\noindent $ L(\theta) = L(\theta) + \lambda C(\theta) $ where $C(\theta)$ is a penalty function with an increasing value as the
constraints are more egregiously violated. $\lambda$ is a penalty coecient that controls how much the constraints are penalised.
This may not respect important constraints.

\noindent \textbf{Relaxation} is a technique where an algorithm tries to find a continuous or unconstrained
optimisation problem to solve instead of a discrete optimisation.

\noindent \textbf{Penalisation} refers to terms which augment an objective function to minimise some other property of
the solution, typically to approximate constrained optimisation.

\noindent \textbf{Properties of the objective function}. A local minimum is any point where the objective function
increases in every direction around that point. An objective function is \textbf{convex} if it has a single, global minimum.

\noindent \textbf{Convex optimisation}

\noindent \textbf{Algorithms}:
\textbf{Direct convex optimisation} techniques, such as least squares,
are used to find the best-fitting solution by minimizing the sum of the squares of the differences
between observed and predicted values. This method is particularly effective for linear regression
problems, where the goal is to determine the linear relationship between variables.

\noindent \textbf{Iterative optimisation}
Make a guess, if the guess is better than the previous guess, keep it, continue until you have reached a good enough solution.
\begin{enumerate}
    \item choose a starting point $x_0$
    \item while objective function changing
    \begin{enumerate}
        \item adjust parameters
        \item evaluate objective function
        \item if better solution found than any so far, record it
    \end{enumerate}
    \item return best parameter set found
\end{enumerate}

\noindent \textbf{Grid search}: The parameter space is split equally in each dimension.
This is very slow as it scales with more dimensions.
If the grid is not fine enough, minima can be missed.

\noindent \textbf{Hyperparameters} are properties which affect the way in which the optimiser finds a solution.

\noindent \textbf{Simple stochastic: random search}: Guess a number $\theta$, check the objective function,
if $L(\theta) \le L(\theta^*)$, then $\theta^* = \theta$.

\noindent \textbf{Metaheuristics}:
There are a number of meta-heuristisc that can be used to improve random search.
\textbf{Locality} which takes advantage of the fact the objective function is likely to have similar values for similar parameter configurations.
\textbf{Temperature} which can change the rate of movement in the parameter space over the course of an optimisation.
\textbf{Population} which can track multiple simultaneous parameter configurations and select among them
\textbf{Memory} which can record good or bad steps in the last and avoid them.

\noindent \textbf{Hill climbing} is a modication of random search, taking steps up hill to get out of local minimum

\noindent \textbf{Simulated annealing} extends hill-climbing with the ability to sometimes randomly go
uphill, instead of always going downhill. It uses a \textbf{temperature schedule} that allows more
uphill steps at the start of the optimisation and fewer ones later in the process. This is used
to overcome ridges and avoid getting stuck in local minima.

\noindent \textbf{Population}: track multiple simultaneous parameters configurations and select/mix among them.
Involves mutation (random variables), natural selection (solution selection) and breeding (interchange between solutions).
each iteration will move solutions slightly by random mutation, cull the weakest solutions and copy the remaining “fittest” solutions to keep the population size constant

\noindent \textbf{Memory} This ineciency can be mitigated
using some form of memory, where the optimiser remembers where “good” and “bad” bits
of the parameters space are, and makes decisions using this memory. In particular, we want
to remember good paths in solution space.

\noindent \textbf{Convergence}
An optimisation algorithm is said to converge to a solution
What can go wrong? Slow progress. Noisy and diverging performance. Getting stuck

























\end{document}
