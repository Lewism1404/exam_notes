\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[margin=2px]{geometry}

\newtheorem{definition}{Definition}
\newtheorem{note}{Note}

\title{Networked Systems}
\author{}
\date{}

\begin{document}

\footnotesize

\subsection*{Database Fundamentals \& Relational Model}

\noindent \textbf{Data} Structured, unstructed, semi-structured

\noindent \textbf{Key Constraints}

\begin{itemize}
    \item \textbf{Superkey (SK)}: A set of attributes that uniquely identifies a tuple in a relation.
    \item \textbf{Candidate Key (CK)}: A minimal superkey.
    \item \textbf{Primary Key (PK)}: A candidate key that is chosen to uniquely identify tuples in a relation; cannot be null.
    \item \textbf{Foreign Key (FK)}: A set of attributes that refers to the primary key of another relation.
\end{itemize}

\noindent \textbf{Entity Integrity Constraint}: Ensures that the primary key is not null.

\noindent \textbf{Referential Integrity Constraint}: Ensures that the foreign key references a valid primary key in another relation

\noindent \textbf{Operations on Relations}

\noindent When an operation violates integrity constraints, the system can:

\begin{itemize}
    \item \textbf{Reject/Abort}: Cancel the violating operation entirely, Maintain database consistency
    \item \textbf{Notify Only}: Complete the operation, Alert user about the violation
    \item \textbf{Automatic Correction}: CASCADE: Propagate changes to maintain referential integrity, SET NULL: Set dependent values to null
    \item \textbf{Custom Handler}: Execute user-defined error correction procedures
    \item \textbf{Silent Failure} (Not Recommended): Ignore the violation, Can lead to data inconsistency
\end{itemize}

\noindent \textbf{Database Constraint Violations}

\begin{itemize}
    \item \textbf{INSERT Violations}: Domain: Values don't match defined data types; Key: Duplicate primary key values; Referential: Foreign key references missing primary key; Entity: NULL values in primary key.
    \item \textbf{DELETE Violations}: Referential integrity when deleting referenced records; Options: Restrict: Block deletion; Propagate: Delete corresponding records; Set Null: Nullify foreign keys; Set Default: Use default values.
    \item \textbf{UPDATE Violations}: Primary Key: Creating duplicate keys; Foreign Key: Setting invalid references; Resolution: Validate constraints first; Choose appropriate action (RESTRICT, CASCADE, etc.); Consider business impact.
\end{itemize}

\noindent \textbf{Guidelines for a Good Design}

\begin{itemize}
    \item The attributes of a relation should make senese
    \item Avoid redundant tuples
    \item Relations should have as a few NULL values as possible
    \item Design relations to avoid fictitious tuples after join
\end{itemize}

\noindent \textbf{Functional Dependency} is a formal metric of the degree of goodness of a relation schema.
X → Y (X uniquely determines Y) holds if whenever two tuples have the same value for X, they must have the same value for Y
If K is a Candiate Key, then K → R (A) for all attributes A in R

\noindent \textbf{Partial Dependency}: A non-key attribute A is partially dependent on the primary key K if A
is dependent on a proper subset of K.

\noindent \textbf{Transitive Dependency}: A non-key attribute A is transitively dependent on the primary key K
if A is dependent on another non-key attribute B, and B is in turn dependent on K.

\noindent \textbf{Normalization}: progressive decomposition of unsatisfactory (bad) relations by breaking
up their attributes into smaller good relations. A prime attribute is an attribute that is part of some candidate key.

\noindent \textbf{First Normal Form (1NF)}: A relation is in 1NF if the domain of each attribute is atomic
(cannot be decomposed) and each tuple is unique. This does not allow nested or multi-valued attributes.

\noindent \textbf{Second Normal Form (2NF)}: A relation is in 2NF if it is in 1NF and all non-key attributes are
fully functionally dependent on the primary key.

\noindent \textbf{Third Normal Form (3NF)}: A relation is in 3NF if it is in 2NF and there are no transitive dependencies.

\noindent \textbf{Boyce-Codd Normal Form (BCNF)}: A relation is in BCNF if it is in 3NF and all determinants are primary keys.

\noindent \textbf{SQL}

\noindent \textbf{Database Schema and Table}: `CREATE SCHEMA' defines a namespace for database objects; `CREATE TABLE' defines the structure of a table.
\noindent \textbf{Data Types}: `INTEGER', `FLOAT', `CHAR', `VARCHAR', `BOOLEAN', `DATE', `TIME', `TIMESTAMP'
\noindent \textbf{Constraints}: `PRIMARY KEY', `FOREIGN KEY', `UNIQUE', `CHECK (condition)', `NOT NULL', `DEFAULT {value}'
\noindent \textbf{Multi-set operators}: `UNION', `INTERSECT', `EXCEPT'

\noindent Any value compared with NULL is unknown, should use `IS NULL' or `IS NOT NULL' to check for NULL values.

\noindent \textbf{Joins}

\begin{itemize}
    \item \textbf{Inner Join}: Returns only the tuples that match the join condition. `WHERE table1 INNER JOIN table2'
    \item \textbf{Left (Outer) Join}: Returns all tuples from the left relation and the matching tuples from the right relation. `WHERE table1 LEFT OUTER JOIN table2 (ON condition)'
    \item \textbf{Right (Outer) Join}: Returns all tuples from the right relation and the matching tuples from the left relation. `WHERE table1 RIGHT OUTER JOIN table2 (ON condition)'
    \item \textbf{Full (Outer) Join}: Returns all tuples from both relations. `WHERE table1 FULL OUTER JOIN table2'
\end{itemize}

\noindent \textbf{Nested Queries}: A query that is nested inside another query.

\begin{itemize}
    \item \textbf{In}: Returns true if the value is in the subquery. `WHERE column IN (SELECT column FROM table2)'
    \item \textbf{Exists}: Returns true if the subquery returns at least one tuple. `WHERE EXISTS (SELECT * FROM table2 WHERE column = value)'
\end{itemize}

\noindent \textbf{Aggregate Functions}: `COUNT', `SUM', `AVG', `MAX', `MIN'

\noindent \textbf{Grouping}: `GROUP BY'

\noindent \textbf{HAVING}: Used to filter groups based on aggregate functions.

\noindent \textbf{Window Functions}: \texttt{ROW\_NUMBER ()}, \texttt{RANK ()}, \texttt{DENSE\_RANK ()}, \texttt{LEAD ()}, \texttt{LAG ()}.
\noindent \textbf{Window Functions}: Window functions perform calculations across a set of rows related to the current row, providing a value for each row instead of summarizing data.
\begin{verbatim}
function_name() OVER (PARTITION BY column1 ORDER BY column2)
\end{verbatim}
\begin{itemize}
    \item \textbf{Function}: The calculation to perform (e.g., \texttt{ROW\_NUMBER ()} or \texttt{SUM ()}).
    \item \textbf{OVER}: Indicates the use of a window function.
    \item \textbf{PARTITION BY}: Groups the data for the function. If omitted, the entire dataset is treated as one group.
    \item \textbf{ORDER BY}: Determines the order of rows within each group.
    \item \textbf{Window Frame}: Defines the rows to operate on. (ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)
    (BETWEEN 1 PRECEDING AND 1 FOLLOWING)
\end{itemize}

\noindent \textbf{Physical Design and Hashing}

\noindent \textbf{Organisation based Optimisation}. Records are grouped together formating a Block, a file is a group of blocks.
blocking factory = $\lfloor \lvert B \rvert / \lvert R \rvert \rfloor$. Number of blocks required = $\lceil \lvert num tuples \rvert / blocking factor \rceil$.
\textbf{Linked Allocation}: Each block has a pointer to the next block.

\noindent \textbf{File Structures}

\noindent \textbf{Heap File}: Blocks are stored in an arbitrary order.

\noindent \textbf{Ordered File}: Blocks are stored in a specific order.
Inserting O (log n) + (move all the blocks),
Retrieving (ordering field) O (log n), Retrieving (non-ordering field) O (n).
Deleting (ordering field) O (n), non-ordering field O (log n).
Can use chain pointers to link records in the same block (sorted linked list)

\noindent \textbf{Hash File}: Blocks are stored in a hash table. Inserting O (1), Retrieving O (n), Deleting O (n).
Can also use chain pointers to link records in the same block (sorted linked list)


\noindent \textbf{Expectation of Random Variable} (Used for Hashing) = $\sum_{i=1}^{n} p_i x_i$


\noindent \textbf{Indexing Methodology}

\noindent \textbf{Dense Index}: An index entry for every record
\textbf{Sparse Index}: An index entry for some records

\noindent \textbf{Index Types}
\begin{itemize}
    \item \textbf{Primary Index}: index field is ordering, key field of a sequential file.
    Anchor records: Sparse index, one per block.
    \item \textbf{Clustering Index}: index field is ordering, non-key field of a sequential file.
    One index per distinct clustering value. Block pointer points at the first block of the cluster.
    The other blocks of the same cluster are contiguous and accesed via chain pointers.
    \item \textbf{Secondary Index}: index field is:
    \begin{itemize}
        \item non-ordering, key field, over an ordered or a non-ordered file.
        \item non-ordering, non-key field, over an ordered or a non-ordered file.
    \end{itemize}
\end{itemize}

\noindent \textbf{Multilevel Index}: We can build a primary index over any index file.

\noindent \textbf{Multilevel Index}: Can become unbalanced

\noindent \textbf{B-Tree: Index on non-ordering key}: B-Tree node order p splits the searching space up to p subspaces

\noindent \textbf{Node Definition:} $\text{Node} := \{P_1, (K_1, Q_1), P_2, (K_2, Q_2), \ldots, P_{p-1}, (K_{p-1}, Q_{p-1}), P_p\}$

\noindent \textbf{B+ Tree: Index on non-ordering key}: Internal nodes have no data pointers, only leaf nodes hold data pointers.
Has higher fan out. Num pointers is blocking factor.

\noindent \textbf{Internal Node Definition:} $p := \{P_1, K_1, P_2, K_2, \ldots, P_{p-1}, K_{p-1}, P_p\}$.
Size of internal node is $p$ (pointer size) + $p-1$ (key size)

\noindent \textbf{Leaf Node Definition:} $p_L := \{(K_1, Q_1), (K_2, Q_2), \ldots, (K_{p_L}, Q_{p_L}), P_{\text{next}}\}$
Size of leaf node is $p$ (pointer size) + $p$ (key size) + $p$ (sibling pointer size)

When you have many duplicate keys, you should use underground (UG) layer, this means the leaf nodes point to blocks of pointers,
which point to the actual data.

\noindent \textbf{External Sorting}: Sorting for large relations stored on disk, that cannot fit into memory.
Divide and Conquer. Split a file of b blocks into L smaller sub-files. Load each sub-file into memory and sort it.
Merge the sorted sub-files into a new sorted file.
Cost is $O(2b(1 + \log_M(L)))$. M is degree of merging, L is the number of initial sorted sub-files.

\noindent \textbf{Strategies for Select}: Linear search (b/2), binary search (log2 b), primary index (t+1) or hash function (1 + n/2) over a key,
hash function over a non key (1 + n (overflow blocks)), primary index over a key in a range query (t + b), clustering index over ordering non-key (t + b/n),
secondary index (B+ Tree) over a non-ordering key (t + 1), non-ordering key (t + m + b)


\noindent \textbf{Strategies for Conjunctive Select} (AND): if an index exists, use the one that generates the smaller result set,
then go through the result set and apply the remaining predicates.

\noindent \textbf{Strategies for Join}: Naive join (no index): Compoute the cartesian product, store the results and for each check the join condition
nested-loop join (no index): For each tuple in the outer relation, check the inner relation for matching tuples
index based nested loop join (index on the inner relation) For each tuple in the outer relation, use the index to find the matching tuples in the inner relation
merge-join (sorted relations) Load a pair of sorted blocks, check the join condition and output the result. Efficient if both relations
are already sorted on the join key.
hash-join (hashed relations) Hash the inner relation and then probe the hash table with the tuples of the outer relation.


\noindent \textbf{Query Optimisation}:

\noindent \textbf{Cost-based Optimisation}: exploit statistical information to estimate the execution cost of a query.
Important is information about each relation and attribute. NDV (Number of Distinct Values).

\noindent \textbf{Selection Selectivity}: $0 \leq sl(A) \leq 1$
\noindent \textbf{Selective Predictions}: Approximation of the selection selectivity. You oculd have no assumption about the data,
could be uniformly distributed

\noindent \textbf{Conjunctive Selectivity} (A = x and B = y): $sl(Q) = sl(A = x) \cdot sl(B = y) \in [0, 1]$

\noindent \textbf{Disjunctive Selectivity} (A = x or B = y): $sl(Q) = sl(A = x) + sl(B = y) - sl(A = x) \cdot sl(B = y) \in [0, 1]$

\noindent \textbf{Selection Selectivity}: $\frac{1}{NDV(A)} = \frac{1}{n}$

\noindent \textbf{Selection Cardinality}: $\left(\frac{1}{NDV(A)}\right) \cdot r = \frac{r}{n}$

\noindent \textbf{Selection Cost Refinement}: Be more accurate: express cost as a function of {s(A)}

\noindent \textbf{Binary Search on sorted relation}: If A is a key, then expected cost is $\log_2(r)$.
If A is not a key, then expected cost is $\log_2(b) + \lceil \frac{r \cdot sl(A)}{f} \rceil - 1$.

\noindent \textbf{Multilevel primary index} with range A >= x: cost: $t + \lceil \frac{r \cdot sl(A)}{f} \rceil - 1$.

\noindent \textbf{Clustering Index} over a non key: cost: $t + \lceil \frac{r \cdot sl(A)}{f} \rceil - 1$.

\noindent \textbf{B+ Tree} over a no ordering non key: cost: $t + m + r \cdot sl(A)$.

\noindent \textbf{B+ Tree} over a no ordering key: cost: $t + 1$.

\noindent \textbf{Multilevel primary index} with range A == x: cost: $t + 1$.

\noindent \textbf{Hash file structure}: cost: $t + O(n)$.

\noindent \textbf{Join Selectivity Theorem}: Given $n = NDV(A, R)$ and $m = NDV(B, S)$: js = $\frac{1}{\max(n, m)}$, jc = $\frac{|R| \cdot |S|}{\max(n, m)}$.


















\end{document}