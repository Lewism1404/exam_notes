\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[margin=2px]{geometry}

\newtheorem{definition}{Definition}
\newtheorem{note}{Note}

\title{Networked Systems}
\author{}
\date{}

\begin{document}

\footnotesize

\subsection*{Common Questions}
Describe what is indicated by a TCP acknowledgement, what are TCP selective acknowledgements, and how do they change what is acknowledged by TCP.\@ Explain why selective acknowledgements are useful?
\begin{itemize}
    \item A TCP acknowledgement (ACK) is sent when a packet arrives that contains new data; the acknowledgement number indicates the next contiguous sequence number expected.
    \item TCP selective acknowledgements (SACK blocks) are a TCP extension that allows a receiver to signal receipt of non-contiguous packets in addition to the standard ACK.\@
    \item SACK blocks are useful because they give the sender information that it needs to avoid unnecessary retransmissions when a triple duplicate ACK is received.
    \item SACK blocks donâ€™t affect the congestion control algorithm; they just change what packets are retransmitted.
\end{itemize}

\noindent Do some background reading and explain what is the TCP receive window and what is the impact of window scaling on the receive window. State also the size of the receive window, in bytes, that will be used by the client in this connection.
\begin{itemize}
    \item The receive window denotes the amount of buffer space the receiver has available to hold data received on a TCP connection.
    \item The range available in the TCP header proved to be too small for receivers on high-speed networks so a window scale of n increases the signalled window by a factor or 2n to allow for larger windows.
\end{itemize}

\noindent Explain the difference between the receive window and the congestion window in a TCP connection. Which is the limiting factor in TCP throughput?
\begin{itemize}
    \item The receive window is the available buffer space at the receiver, the congestion window is an estimate of the available network capacity. 
    Performance is limited by whichever is smaller; the receiver needs enough buffering to match the network if the full performance is to be reached.
\end{itemize}

\noindent Consider a modified version of TCP that overlaps these twophases, where the client provides some data as an additional parameter to the connect ()
function which is sent in the TCP segment that has the SYN bit set, with the response being
returned in the SYN+ACK segment. State what would be the benefit of this idea and discuss
why it is not feasible in practise.
\begin{itemize}
    \item This is TCP Fast Open, Some benefits are: Reduce latency as data can be exchanged immediately, reduce the number of round trips, and reduce the number of packets sent.
    \item The main issue is that it is not secure, SYN packets can be easily spoofed. Attackers could resend previously captured SYN packets, causing servers to process old requests (Replay Attack).
    \item Many networks block SYN packets, so this would not work on many networks.
\end{itemize}

Briefly discuss the potential benefits and risks of remembering the congestion window.
\begin{itemize}
    \item Benefits: Faster connection establishment, less congestion on the network.
    \item Risks: If the network conditions change, the congestion window may not be appropriate, leading to increased latency or packet loss. 
    \item Risks: If some flows start with a high congestion window, they may starve other flows.
\end{itemize}

Discuss why and how server push can improve performance,
giving an example to illustrate your argument, and stating by what metric are improvements
measured. Explain in what circumstances server push might not help, and might even hurt,
performance. Finally, state whether you think HTTP server push is likely to be a net benefit
overall, justifying your answer.
\begin{itemize}
    \item Benefits: Server push can improve performance by allowing the server to send data to the client before the client requests it.
    \item Example: A web page may request an HTML file, but the server can push the file and its associated resources to the client before the client requests it.
    \item Metrics: Throughput, latency, and resource usage.
    \item Risks: Server push may not help if the client already has the data, or if the network conditions are such that the client is already receiving data at a high rate.
    \item Risks: Server push may hurt performance if it causes the client to use more resources than it would otherwise.
    \item Risks: Cache redundancy, as the server may push the same data that has already been cached by the client.
    \item Overall, HTTP server push is likely to be a net benefit overall, as it can reduce latency and improve performance.
\end{itemize}

Discuss the trade-offs that would have been considered when selecting the size
of the IPv6 address.
\begin{itemize}
    \item Benefits: 128-bit address space, perhaps too large for the foreseeable future, but it is unlikely that we will run out of addresses.
\end{itemize}

People use domain names (e.g., google.com) to identify sites, with software applications
performing a DNS lookup to convert these into IP addresses prior to use. The time it takes
to perform such a DNS lookup can vary significantly. Explain what causes this variation.
\begin{itemize}
    \item The time it takes to perform a DNS lookup can vary significantly due to the distance between the client and the DNS server, the load on the DNS server, and the time it takes for the DNS server to respond.
    \item DNS caching, different website can cache for different times, and the time it takes for the DNS server to respond can vary.
\end{itemize}


\end{document}